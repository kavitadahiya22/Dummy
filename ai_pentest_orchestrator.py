#!/usr/bin/env python3
"""
AI-Powered Penetration Testing Orchestrator
Uses OpenAI and DeepSeek to intelligently coordinate penetration testing tools
"""

import os
import sys
import json
import time
import asyncio
import datetime
import subprocess
import logging
from pathlib import Path
from typing import Dict, List, Any
import requests

# AI Libraries
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ai_pentest.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AIPentestOrchestrator:
    def __init__(self, target_url, openai_api_key=None, deepseek_api_key=None):
        self.target_url = target_url
        self.openai_api_key = openai_api_key or os.getenv('OPENAI_API_KEY')
        self.deepseek_api_key = deepseek_api_key or os.getenv('DEEPSEEK_API_KEY')
        
        # Initialize AI clients
        self.setup_ai_clients()
        
        # Paths and directories
        self.tools_dir = Path('./tools')
        self.results_dir = Path('./results')
        self.reports_dir = Path('./reports')
        self.results_dir.mkdir(exist_ok=True)
        self.reports_dir.mkdir(exist_ok=True)
        
        # OpenSearch configuration
        self.opensearch_url = os.getenv('OPENSEARCH_URL', 'http://localhost:9200')
        self.dashboard_url = os.getenv('OPENSEARCH_DASHBOARD_URL', 'http://localhost:5601')
        
        # Test results storage
        self.test_results = {}
        self.ai_analysis = {}
        self.vulnerability_insights = []
        
        logger.info(f"ğŸ¤– AI Pentest Orchestrator initialized")
        logger.info(f"ğŸ¯ Target: {self.target_url}")
        logger.info(f"ğŸ“Š OpenSearch: {self.opensearch_url}")
        logger.info(f"ğŸ“ˆ Dashboard: {self.dashboard_url}")
    
    def setup_ai_clients(self):
        """Setup AI clients for OpenAI and DeepSeek"""
        if self.openai_api_key and OPENAI_AVAILABLE:
            openai.api_key = self.openai_api_key
            self.openai_client = openai
            logger.info("âœ… OpenAI client initialized")
        else:
            self.openai_client = None
            logger.warning("âš ï¸ OpenAI not available (missing API key or library)")
        
        # DeepSeek setup (using OpenAI-compatible API)
        if self.deepseek_api_key:
            self.deepseek_client = openai.OpenAI(
                api_key=self.deepseek_api_key,
                base_url="https://api.deepseek.com/v1"
            )
            logger.info("âœ… DeepSeek client initialized")
        else:
            self.deepseek_client = None
            logger.warning("âš ï¸ DeepSeek not available (missing API key)")
    
    async def ai_analyze_target(self) -> Dict[str, Any]:
        """Use AI to analyze the target and suggest testing strategies"""
        logger.info("ğŸ¤– AI analyzing target for optimal testing strategy...")
        
        analysis_prompt = f"""
        Analyze this web application target for penetration testing: {self.target_url}
        
        Based on the URL and common web application patterns, suggest:
        1. Most likely vulnerabilities to test for
        2. Priority order of security tools to use
        3. Specific attack vectors to focus on
        4. Expected findings based on the application type
        
        Target URL: {self.target_url}
        
        Provide a structured JSON response with:
        - recommended_tools: list of tools in priority order
        - vulnerability_focus: list of vulnerability types to prioritize
        - attack_vectors: specific attack methods to try
        - risk_assessment: expected risk level (high/medium/low)
        """
        
        ai_strategy = await self.query_ai_models(analysis_prompt)
        
        try:
            # Try to parse as JSON, fallback to text analysis
            if ai_strategy and 'recommended_tools' in ai_strategy:
                return ai_strategy
            else:
                # Fallback strategy based on URL analysis
                return self.fallback_target_analysis()
        except:
            return self.fallback_target_analysis()
    
    def fallback_target_analysis(self) -> Dict[str, Any]:
        """Fallback analysis when AI is not available"""
        return {
            "recommended_tools": ["nmap", "nikto", "nuclei", "sqlmap", "hydra", "zap"],
            "vulnerability_focus": ["SQL Injection", "XSS", "Authentication Bypass", "Directory Traversal"],
            "attack_vectors": ["Input validation", "Authentication mechanisms", "Session management"],
            "risk_assessment": "medium",
            "ai_analysis": "Fallback analysis - comprehensive testing recommended"
        }
    
    async def query_ai_models(self, prompt: str) -> Dict[str, Any]:
        """Query both OpenAI and DeepSeek for analysis"""
        responses = {}
        
        # Query OpenAI if available
        if self.openai_client:
            try:
                response = await self.query_openai(prompt)
                responses['openai'] = response
                logger.info("âœ… OpenAI analysis completed")
            except Exception as e:
                logger.error(f"âŒ OpenAI query failed: {e}")
        
        # Query DeepSeek if available
        if self.deepseek_client:
            try:
                response = await self.query_deepseek(prompt)
                responses['deepseek'] = response
                logger.info("âœ… DeepSeek analysis completed")
            except Exception as e:
                logger.error(f"âŒ DeepSeek query failed: {e}")
        
        # Combine and return best response
        return self.combine_ai_responses(responses)
    
    async def query_openai(self, prompt: str) -> str:
        """Query OpenAI for analysis"""
        try:
            response = self.openai_client.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are a cybersecurity expert specializing in penetration testing."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.3
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"OpenAI API error: {e}")
            return None
    
    async def query_deepseek(self, prompt: str) -> str:
        """Query DeepSeek for analysis"""
        try:
            response = self.deepseek_client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": "You are an AI security analyst expert in penetration testing and vulnerability assessment."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.3
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"DeepSeek API error: {e}")
            return None
    
    def combine_ai_responses(self, responses: Dict[str, str]) -> Dict[str, Any]:
        """Combine responses from multiple AI models"""
        if not responses:
            return self.fallback_target_analysis()
        
        # For now, prefer DeepSeek if available, fallback to OpenAI
        primary_response = responses.get('deepseek') or responses.get('openai')
        
        if primary_response:
            try:
                # Try to extract structured data from AI response
                if '{' in primary_response and '}' in primary_response:
                    start = primary_response.find('{')
                    end = primary_response.rfind('}') + 1
                    json_str = primary_response[start:end]
                    return json.loads(json_str)
            except:
                pass
        
        # Fallback to default analysis
        return self.fallback_target_analysis()
    
    async def ai_orchestrated_pentest(self) -> bool:
        """Run AI-orchestrated penetration testing"""
        logger.info("ğŸš€ Starting AI-Orchestrated Penetration Testing")
        logger.info("=" * 70)
        
        try:
            # Phase 1: AI Target Analysis
            ai_strategy = await self.ai_analyze_target()
            self.ai_analysis = ai_strategy
            
            logger.info("ğŸ¤– AI Strategy Analysis:")
            logger.info(f"  Risk Assessment: {ai_strategy.get('risk_assessment', 'Unknown')}")
            logger.info(f"  Recommended Tools: {ai_strategy.get('recommended_tools', [])}")
            logger.info(f"  Focus Areas: {ai_strategy.get('vulnerability_focus', [])}")
            
            # Phase 2: Wait for services
            await self.wait_for_services()
            
            # Phase 3: Execute tools based on AI recommendations
            recommended_tools = ai_strategy.get('recommended_tools', [])
            await self.execute_ai_recommended_tools(recommended_tools)
            
            # Phase 4: AI Analysis of Results
            await self.ai_analyze_results()
            
            # Phase 5: Generate comprehensive reports
            await self.generate_ai_enhanced_reports()
            
            # Phase 6: Send to OpenSearch Dashboard
            await self.send_to_opensearch_dashboard()
            
            logger.info("ğŸ‰ AI-Orchestrated Penetration Testing Complete!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ AI Pentest failed: {e}")
            return False
    
    async def wait_for_services(self):
        """Wait for Docker services to be ready"""
        services = [
            (self.target_url, "Target Application"),
            (self.opensearch_url, "OpenSearch"),
            (self.dashboard_url, "OpenSearch Dashboard")
        ]
        
        for url, name in services:
            await self.wait_for_service(url, name)
    
    async def wait_for_service(self, url: str, name: str, timeout: int = 300):
        """Wait for a specific service to become available"""
        logger.info(f"â³ Waiting for {name} at {url}")
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            try:
                response = requests.get(url, timeout=5)
                if response.status_code < 500:
                    logger.info(f"âœ… {name} is ready")
                    return True
            except requests.exceptions.RequestException:
                pass
            
            await asyncio.sleep(5)
        
        logger.warning(f"âš ï¸ {name} not ready after {timeout}s, continuing anyway")
        return False
    
    async def execute_ai_recommended_tools(self, recommended_tools: List[str]):
        """Execute penetration testing tools based on AI recommendations"""
        logger.info("ğŸ”§ Executing AI-recommended tools...")
        
        # Map tool names to script files
        tool_mapping = {
            'nmap': 'tools/nmap.py',
            'nikto': 'tools/nikto.py',
            'nuclei': 'tools/nuclei.py',
            'sqlmap': 'tools/sqlmap.py',
            'hydra': 'tools/hydra.py',
            'zap': 'tools/zap.py',
            'amass': 'tools/amass.py',
            'bloodhound': 'tools/bloodhound.py',
            'crackmapexec': 'tools/crackmapexec.py',
            'metasploit': 'tools/metasploit.py'
        }
        
        # Execute tools in order of AI recommendation
        for tool_name in recommended_tools:
            if tool_name in tool_mapping:
                script_path = tool_mapping[tool_name]
                if Path(script_path).exists():
                    await self.execute_tool(tool_name, script_path)
                else:
                    logger.warning(f"âš ï¸ Tool script not found: {script_path}")
            else:
                logger.warning(f"âš ï¸ Unknown tool: {tool_name}")
    
    async def execute_tool(self, tool_name: str, script_path: str):
        """Execute a specific penetration testing tool"""
        logger.info(f"ğŸ”§ Running {tool_name}")
        
        try:
            # Run the tool script
            result = subprocess.run(
                [sys.executable, script_path, self.target_url],
                capture_output=True,
                text=True,
                timeout=300,
                cwd=Path.cwd()
            )
            
            # Store results
            self.test_results[tool_name] = {
                'status': 'success' if result.returncode == 0 else 'failed',
                'stdout': result.stdout,
                'stderr': result.stderr,
                'returncode': result.returncode,
                'timestamp': datetime.datetime.now().isoformat(),
                'findings_count': self.count_findings(result.stdout)
            }
            
            logger.info(f"âœ… {tool_name} completed - {self.test_results[tool_name]['findings_count']} findings")
            
        except subprocess.TimeoutExpired:
            logger.warning(f"â° {tool_name} timed out")
            self.test_results[tool_name] = {
                'status': 'timeout',
                'timestamp': datetime.datetime.now().isoformat(),
                'findings_count': 0
            }
        except Exception as e:
            logger.error(f"âŒ {tool_name} failed: {e}")
            self.test_results[tool_name] = {
                'status': 'error',
                'error': str(e),
                'timestamp': datetime.datetime.now().isoformat(),
                'findings_count': 0
            }
    
    def count_findings(self, output: str) -> int:
        """Count findings/vulnerabilities in tool output"""
        if not output:
            return 0
        
        # Simple heuristic to count findings
        finding_indicators = [
            'vulnerability', 'exploit', 'injection', 'xss', 'csrf', 
            'open port', 'weak', 'insecure', 'exposed', 'critical'
        ]
        
        count = 0
        for line in output.lower().split('\n'):
            if any(indicator in line for indicator in finding_indicators):
                count += 1
        
        return count
    
    async def ai_analyze_results(self):
        """Use AI to analyze the penetration testing results"""
        logger.info("ğŸ¤– AI analyzing penetration testing results...")
        
        # Prepare results summary for AI analysis
        results_summary = self.prepare_results_for_ai()
        
        analysis_prompt = f"""
        Analyze these penetration testing results and provide insights:
        
        Target: {self.target_url}
        Results Summary: {json.dumps(results_summary, indent=2)}
        
        Please provide:
        1. Overall security posture assessment
        2. Critical vulnerabilities that need immediate attention
        3. Risk prioritization recommendations
        4. Suggested remediation steps
        5. Compliance implications
        
        Format as JSON with clear sections for dashboard visualization.
        """
        
        ai_insights = await self.query_ai_models(analysis_prompt)
        self.vulnerability_insights = ai_insights
        
        logger.info("âœ… AI vulnerability analysis completed")
    
    def prepare_results_for_ai(self) -> Dict[str, Any]:
        """Prepare test results for AI analysis"""
        summary = {
            'total_tools_run': len(self.test_results),
            'successful_tools': len([r for r in self.test_results.values() if r.get('status') == 'success']),
            'total_findings': sum(r.get('findings_count', 0) for r in self.test_results.values()),
            'tools_summary': {}
        }
        
        for tool_name, result in self.test_results.items():
            summary['tools_summary'][tool_name] = {
                'status': result.get('status'),
                'findings': result.get('findings_count', 0),
                'key_output': result.get('stdout', '')[:500] if result.get('stdout') else ''
            }
        
        return summary
    
    async def generate_ai_enhanced_reports(self):
        """Generate comprehensive reports with AI insights"""
        logger.info("ğŸ“„ Generating AI-enhanced reports...")
        
        # Save raw results
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        results_file = self.results_dir / f'ai_pentest_results_{timestamp}.json'
        
        comprehensive_results = {
            'metadata': {
                'target_url': self.target_url,
                'timestamp': timestamp,
                'ai_strategy': self.ai_analysis,
                'ai_insights': self.vulnerability_insights
            },
            'test_results': self.test_results,
            'summary': {
                'total_tools': len(self.test_results),
                'successful_tools': len([r for r in self.test_results.values() if r.get('status') == 'success']),
                'total_findings': sum(r.get('findings_count', 0) for r in self.test_results.values())
            }
        }
        
        with open(results_file, 'w') as f:
            json.dump(comprehensive_results, f, indent=2, default=str)
        
        logger.info(f"âœ… Results saved to {results_file}")
        
        # Generate PDF report with AI insights
        await self.generate_ai_pdf_report(results_file)
        
        return results_file
    
    async def generate_ai_pdf_report(self, results_file: Path):
        """Generate PDF report with AI insights"""
        try:
            env = os.environ.copy()
            env['RESULTS_FILE'] = str(results_file)
            env['AI_ENHANCED'] = 'true'
            
            result = subprocess.run(
                [sys.executable, 'pdf_report_generator.py'],
                env=env,
                capture_output=True,
                text=True,
                timeout=180
            )
            
            if result.returncode == 0:
                logger.info("âœ… AI-enhanced PDF report generated")
            else:
                logger.warning(f"âš ï¸ PDF generation had issues: {result.stderr}")
                
        except Exception as e:
            logger.error(f"âŒ PDF generation failed: {e}")
    
    async def send_to_opensearch_dashboard(self):
        """Send results to OpenSearch for dashboard visualization"""
        logger.info("ğŸ“Š Sending results to OpenSearch Dashboard...")
        
        try:
            # Setup OpenSearch integration
            integration_script = Path('opensearch_integration.py')
            if integration_script.exists():
                result = subprocess.run(
                    [sys.executable, str(integration_script)],
                    capture_output=True,
                    text=True,
                    timeout=120
                )
                
                if result.returncode == 0:
                    logger.info("âœ… OpenSearch integration completed")
                    logger.info(f"ğŸ¯ Dashboard URL: {self.dashboard_url}/app/dashboards")
                else:
                    logger.warning(f"âš ï¸ OpenSearch integration issues: {result.stderr}")
            else:
                logger.error("âŒ OpenSearch integration script not found")
                
        except Exception as e:
            logger.error(f"âŒ OpenSearch integration failed: {e}")
    
    def print_final_summary(self):
        """Print comprehensive final summary"""
        logger.info("ğŸ‰ AI-Powered Penetration Testing Complete!")
        logger.info("=" * 70)
        
        total_findings = sum(r.get('findings_count', 0) for r in self.test_results.values())
        successful_tools = len([r for r in self.test_results.values() if r.get('status') == 'success'])
        
        logger.info(f"ğŸ¯ Target: {self.target_url}")
        logger.info(f"ğŸ¤– AI Models: {'OpenAI + DeepSeek' if self.openai_client and self.deepseek_client else 'Fallback Analysis'}")
        logger.info(f"ğŸ”§ Tools Executed: {successful_tools}/{len(self.test_results)}")
        logger.info(f"ğŸ” Total Findings: {total_findings}")
        
        logger.info("\nğŸ“Š Access Points:")
        logger.info(f"  â€¢ Dashboard: {self.dashboard_url}/app/dashboards")
        logger.info(f"  â€¢ OpenSearch: {self.opensearch_url}")
        logger.info(f"  â€¢ Results: ./results/")
        logger.info(f"  â€¢ Reports: ./reports/")
        
        if self.ai_analysis:
            risk_level = self.ai_analysis.get('risk_assessment', 'unknown')
            logger.info(f"\nğŸ¤– AI Risk Assessment: {risk_level.upper()}")
        
        logger.info("\nğŸ¯ Next Steps:")
        logger.info("  1. Review the AI-enhanced dashboard for real-time insights")
        logger.info("  2. Examine the PDF report with AI vulnerability analysis")
        logger.info("  3. Prioritize remediation based on AI recommendations")
        logger.info("  4. Schedule follow-up testing to validate fixes")

async def main():
    """Main async function for AI-powered penetration testing"""
    import argparse
    
    parser = argparse.ArgumentParser(description="AI-Powered Penetration Testing Orchestrator")
    parser.add_argument("target_url", help="Target URL to test")
    parser.add_argument("--openai-key", help="OpenAI API key")
    parser.add_argument("--deepseek-key", help="DeepSeek API key")
    
    args = parser.parse_args()
    
    print("ğŸ¤– AI-POWERED PENETRATION TESTING ORCHESTRATOR")
    print("ğŸ¯ Enhanced with OpenAI + DeepSeek Intelligence")
    print("ğŸ“Š Real-time OpenSearch Dashboard Integration")
    print("=" * 70)
    
    # Initialize AI orchestrator
    orchestrator = AIPentestOrchestrator(
        target_url=args.target_url,
        openai_api_key=args.openai_key,
        deepseek_api_key=args.deepseek_key
    )
    
    # Run AI-orchestrated penetration testing
    success = await orchestrator.ai_orchestrated_pentest()
    
    # Print final summary
    orchestrator.print_final_summary()
    
    return 0 if success else 1

if __name__ == "__main__":
    # Handle both direct execution and Docker environment
    if len(sys.argv) == 1 and os.getenv('TARGET_URL'):
        sys.argv.append(os.getenv('TARGET_URL'))
    
    # Run async main
    import asyncio
    sys.exit(asyncio.run(main()))
